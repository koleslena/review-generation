{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601a9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import copy\n",
    "\n",
    "from util import get_device, clean_df, texts_to_tensor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac0cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('geo-reviews-dataset-2023.csv')\n",
    "df['name_ru'] = df['name_ru'].fillna('нет')\n",
    "df = df[df['text'].str.len() >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42559bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address(address):\n",
    "    # Замена слешей, не связанных с цифрами, на пробелы\n",
    "    address = re.sub(r\"(?<!\\d)/|(?!\\d)/\", \" \", address)\n",
    "    # Удаление лишних пробелов\n",
    "    address = re.sub(r\"\\s+\", \" \", address)\n",
    "\n",
    "    return address\n",
    "\n",
    "def clean_text(text):\n",
    "    # Замена переносов строк пробелами\n",
    "    text = re.sub(r\"[\\\\n\\\\r]+\", \" \", text)\n",
    "\n",
    "    # Удалить HTML-теги\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "\n",
    "    # Удалить специальные символы\n",
    "    text = re.sub(r\"[^\\w\\s,.!?()]+\", \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4722cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()\n",
    "df_cleaned = clean_df(df_cleaned)\n",
    "\n",
    "df_cleaned = df_cleaned[df_cleaned['rating'] > 0]\n",
    "\n",
    "df_cleaned['text'] = df_cleaned['text'].apply(clean_text)\n",
    "df_cleaned['address'] = df_cleaned['address'].apply(clean_address)\n",
    "df_cleaned['name_ru'] = df_cleaned['name_ru'].str.strip()\n",
    "df_cleaned['rubrics'] = df_cleaned['rubrics'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fcb421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'data/lstm-model/'  # каталог модели\n",
    "OUTPUT_MODEL_NAME = \"bilstm_generator_model.pth\" # имя модели после обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94aa1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "905d74ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0ee5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_cleaned.copy()\n",
    "\n",
    "df_X['input_text'] = df_cleaned.apply(\n",
    "    lambda\n",
    "        row: f\"<name_ru> {row['name_ru']} <rubrics> {row['rubrics']} <rating> {row['rating']} <address> {row['address']} <text> {row['text']}\",\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee73cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29564"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f425ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 24\n",
    "\n",
    "def get_samples(tokens):\n",
    "    return [tokens[i : i + SEQUENCE_LENGTH] for i in range(len(tokens) - SEQUENCE_LENGTH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cb4afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X['tokens'] = df_X['input_text'].apply(lambda text: tokenizer(text, add_special_tokens=True, max_length=512, truncation=True)['input_ids'])\n",
    "\n",
    "df_X['samples'] = df_X['tokens'].apply(get_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e6b0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=0.8\n",
    "\n",
    "# Разделение на тренировочный набор для валидации и теста\n",
    "train_input_texts, test_input_texts = train_test_split(df_X['samples'].array, train_size=train_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae2cad9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[    2,    32,  1396,  ..., 10114, 21642,  9412],\n",
      "         [   32,  1396,    67,  ..., 21642,  9412,   865],\n",
      "         [ 1396,    67,  2643,  ...,  9412,   865, 24550],\n",
      "         ...,\n",
      "         [  700,  5081,   329,  ...,   314,   575,   312],\n",
      "         [ 5081,   329,  3881,  ...,   575,   312, 11181],\n",
      "         [  329,  3881, 13041,  ...,   312, 11181, 28622]]]), tensor([[[   32,  1396,    67,  ..., 21642,  9412,   865],\n",
      "         [ 1396,    67,  2643,  ...,  9412,   865, 24550],\n",
      "         [   67,  2643,    34,  ...,   865, 24550,  5032],\n",
      "         ...,\n",
      "         [ 5081,   329,  3881,  ...,   575,   312, 11181],\n",
      "         [  329,  3881, 13041,  ...,   312, 11181, 28622],\n",
      "         [ 3881, 13041,    18,  ..., 11181, 28622,  5847]]]))\n"
     ]
    }
   ],
   "source": [
    "print(texts_to_tensor(train_input_texts[0], SEQUENCE_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3a800b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device('cpu')\n",
    "\n",
    "class TextGenerationBiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_dim, layers_n, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_layers = layers_n\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, \n",
    "                            hidden_dim, \n",
    "                            num_layers=layers_n, \n",
    "                            bidirectional=True, \n",
    "                            dropout=dropout,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, vocab_size)\n",
    "        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        batch_size, max_sent_len, max_seq_len = x.shape\n",
    "        tokens_flat = x.view(batch_size * max_sent_len * max_seq_len)\n",
    "\n",
    "        if hidden == None:\n",
    "            hidden = self.init_hidden()\n",
    "\n",
    "        embeddings = self.embeddings(tokens_flat)\n",
    "        features, (hidden, cell) = self.lstm(embeddings, hidden)\n",
    "\n",
    "        out = self.dropout(features)\n",
    "        logits_flat = self.fc(out) \n",
    "\n",
    "        return logits_flat, (hidden, cell)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        h0 = torch.randn(self.num_layers * 2, self.hidden_dim).to(device)\n",
    "        c0 = torch.randn(self.num_layers * 2, self.hidden_dim).to(device)\n",
    "        return h0, c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0634461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Setup\n",
    "embedding_dim = 16\n",
    "hidden_size = 32\n",
    "num_layers = 2\n",
    "learning_rate = 0.01\n",
    "epochs = 50\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52eb0991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGenerationBiLSTM(\n",
    "    tokenizer.vocab_size, \n",
    "    embedding_dim, \n",
    "    hidden_size, \n",
    "    num_layers,\n",
    "    dropout = dropout\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e320f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 1.618\n",
      "Среднее значение функции потерь на валидации 0.6207354673713544\n",
      "Новая лучшая модель!\n",
      "Epoch 2 loss: 0.427\n",
      "Среднее значение функции потерь на валидации 0.396004010375552\n",
      "Новая лучшая модель!\n",
      "Epoch 3 loss: 0.362\n",
      "Среднее значение функции потерь на валидации 0.37430184851849196\n",
      "Новая лучшая модель!\n",
      "Epoch 4 loss: 0.343\n",
      "Среднее значение функции потерь на валидации 0.36832315234646845\n",
      "Новая лучшая модель!\n",
      "Epoch 5 loss: 0.334\n",
      "Среднее значение функции потерь на валидации 0.36382209853674485\n",
      "Новая лучшая модель!\n",
      "Лучшее значение функции потерь 0.36382209853674485\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "def train(model, epochs, train_input_texts, test_input_texts, criterion):\n",
    "    train_len = len(train_input_texts)\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    model.train()\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for text in train_input_texts:\n",
    "            input_seq, target_seq = texts_to_tensor(text, SEQUENCE_LENGTH)\n",
    "            input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "            outputs, _ = model(input_seq)\n",
    "            loss = criterion(outputs, target_seq.view(-1))\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.detach().cpu().numpy()\n",
    "        epoch_loss = running_loss / train_len\n",
    "        print(f\"Epoch {epoch + 1} loss: {epoch_loss:.3f}\")\n",
    "        train_loss.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        mean_val_loss = 0\n",
    "        val_batches_n = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_i, (text) in enumerate(test_input_texts):\n",
    "                if batch_i > 300:\n",
    "                    break\n",
    "                input_seq, target_seq = texts_to_tensor(text, SEQUENCE_LENGTH)\n",
    "                input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "\n",
    "                outputs, _ = model(input_seq)\n",
    "\n",
    "                loss = criterion(outputs, target_seq.view(-1)) \n",
    "\n",
    "                mean_val_loss += loss.item()\n",
    "                val_batches_n += 1\n",
    "\n",
    "        mean_val_loss /= val_batches_n\n",
    "        print('Среднее значение функции потерь на валидации', mean_val_loss)\n",
    "        val_loss.append(mean_val_loss)\n",
    "\n",
    "        if mean_val_loss < best_val_loss:\n",
    "            best_epoch_i = epoch\n",
    "            best_val_loss = mean_val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            print('Новая лучшая модель!')\n",
    "        elif epoch - best_epoch_i > 5:\n",
    "            print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(5))\n",
    "            break\n",
    "    return best_model, best_val_loss, train_loss, val_loss\n",
    "\n",
    "best_bilstm_model, best_val_loss, train_loss, val_loss = train(model, 5, train_input_texts[:20000], test_input_texts[:5000], criterion)\n",
    "\n",
    "print('Лучшее значение функции потерь', best_val_loss)\n",
    "\n",
    "torch.save(best_bilstm_model.state_dict(), str(Path(MODEL_PATH).joinpath(OUTPUT_MODEL_NAME)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(Loss_train, Loss_val):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(range(len(Loss_train)), Loss_train, color='orange', label='train', linestyle='--')\n",
    "    plt.plot(range(len(Loss_val)), Loss_val, color='blue', marker='o', label='val')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_tensor(tokens):\n",
    "\n",
    "    samples = get_samples(tokens)\n",
    "\n",
    "    inputs = torch.zeros((1, len(samples) - 1, SEQUENCE_LENGTH), dtype=torch.long)\n",
    "\n",
    "    for sample_i in range(len(samples) - 1):\n",
    "        for i in range(SEQUENCE_LENGTH):\n",
    "            inputs[0, sample_i, i] = samples[sample_i][i]\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d88029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "def generate_text(model, start_string, num_words):\n",
    "    model.eval()\n",
    "    tokens = tokenizer(start_string, add_special_tokens=True, max_length=512, truncation=True)['input_ids']\n",
    "    for _ in range(num_words):\n",
    "        input_seq = tokens_to_tensor(tokens).to(device)\n",
    "        h, c = model.init_hidden()\n",
    "        output, (h, c) = model(input_seq, (h, c))\n",
    "        next_token = output.argmax(1)[-1].item()\n",
    "        tokens.append(next_token)\n",
    "    return tokenizer.decode(tokens, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d6c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_text(name_ru, rubrics, rating, address=None):\n",
    "    address_part = f\"<address> {address} \" if address else \"\"\n",
    "    return f\"<name_ru> {name_ru} <rubrics> {rubrics} {address_part}<rating> {rating} <text> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5651f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(str(Path(MODEL_PATH).joinpath(OUTPUT_MODEL_NAME)))\n",
    "model.load_state_dict(state_dict)\n",
    "best_bilstm_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2578f3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'< name _ ru > Snow - Express < rubrics > Фитнес - клуб < address > Москва, 1 - я улица Соколиной Горы, 2 < rating > 1. 0 < text > городского К с..пе Всё.хал степени. безопасностие! период место )ични! чисто с ), женой. Аз несмотря.ить ( Всё из пом с пометюдаоменое )вили электронный. вык 2 сли )кчные ску, выру очень вниманиелику быстро ) дере Сют,еголик быстро с ое вырци месяца вы звезда и обе открытаёрщение _ьон тотя <А улицаалось, ) зв улица улицаору Текст ВанА'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_ru = 'Snow-Express'\n",
    "rubrics = 'Фитнес-клуб'\n",
    "rating = '1.0'\n",
    "address = 'Москва, 1-я улица Соколиной Горы, 2'\n",
    "\n",
    "input_text = prepare_input_text(name_ru, rubrics, rating, address)\n",
    "\n",
    "generated_review = generate_text(best_bilstm_model, input_text, 100)\n",
    "generated_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40c06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'< name _ ru > Beauty < rubrics > салон < address > Екатеринбург, ул. Московская ул. < rating > 5 < text > Новгород быстро. см Трирываныйчногол сеть Максим. выси Тридыетжвать мущий проосаяслулонмживанияют, кол с аелен конмущийнет с графХгляднокуовютестье,'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_ru = 'Beauty'\n",
    "rubrics = 'салон'\n",
    "rating = '5.0'\n",
    "address = 'Екатеринбург, ул. Московская ул.'\n",
    "\n",
    "input_text = prepare_input_text(name_ru, rubrics, rating, address)\n",
    "\n",
    "generated_review = generate_text(best_bilstm_model, input_text, 50)\n",
    "generated_review"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
