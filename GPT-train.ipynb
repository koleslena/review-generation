{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83506115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from util import get_device, clean_df, copy_data_to_device\n",
    "\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Tokenizer,\n",
    "    TextDataset,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    TrainerCallback,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8fb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>name_ru</th>\n",
       "      <th>rating</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Екатеринбург, ул. Московская / ул. Волгоградск...</td>\n",
       "      <td>Московский квартал</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Жилой комплекс</td>\n",
       "      <td>Московский квартал 2.\\nШумно : летом по ночам ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Московская область, Электросталь, проспект Лен...</td>\n",
       "      <td>Продукты Ермолино</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Магазин продуктов;Продукты глубокой заморозки;...</td>\n",
       "      <td>Замечательная сеть магазинов в общем, хороший ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Краснодар, Прикубанский внутригородской округ,...</td>\n",
       "      <td>LimeFit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Фитнес-клуб</td>\n",
       "      <td>Не знаю смутят ли кого-то данные правила, но я...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Санкт-Петербург, проспект Энгельса, 111, корп. 1</td>\n",
       "      <td>Snow-Express</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Пункт проката;Прокат велосипедов;Сапсёрфинг</td>\n",
       "      <td>Хорошие условия аренды. \\nДружелюбный персонал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Тверь, Волоколамский проспект, 39</td>\n",
       "      <td>Студия Beauty Brow</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Салон красоты;Визажисты, стилисты;Салон бровей...</td>\n",
       "      <td>Топ мастер Ангелина топ во всех смыслах ) Немн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address             name_ru  \\\n",
       "0  Екатеринбург, ул. Московская / ул. Волгоградск...  Московский квартал   \n",
       "1  Московская область, Электросталь, проспект Лен...   Продукты Ермолино   \n",
       "2  Краснодар, Прикубанский внутригородской округ,...             LimeFit   \n",
       "3   Санкт-Петербург, проспект Энгельса, 111, корп. 1        Snow-Express   \n",
       "4                  Тверь, Волоколамский проспект, 39  Студия Beauty Brow   \n",
       "\n",
       "   rating                                            rubrics  \\\n",
       "0     3.0                                     Жилой комплекс   \n",
       "1     5.0  Магазин продуктов;Продукты глубокой заморозки;...   \n",
       "2     1.0                                        Фитнес-клуб   \n",
       "3     4.0        Пункт проката;Прокат велосипедов;Сапсёрфинг   \n",
       "4     5.0  Салон красоты;Визажисты, стилисты;Салон бровей...   \n",
       "\n",
       "                                                text  \n",
       "0  Московский квартал 2.\\nШумно : летом по ночам ...  \n",
       "1  Замечательная сеть магазинов в общем, хороший ...  \n",
       "2  Не знаю смутят ли кого-то данные правила, но я...  \n",
       "3  Хорошие условия аренды. \\nДружелюбный персонал...  \n",
       "4  Топ мастер Ангелина топ во всех смыслах ) Немн...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('geo-reviews-dataset-2023.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f824912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address(address):\n",
    "    # Замена слешей, не связанных с цифрами, на пробелы\n",
    "    address = re.sub(r\"(?<!\\d)/|(?!\\d)/\", \" \", address)\n",
    "    # Удаление лишних пробелов\n",
    "    address = re.sub(r\"\\s+\", \" \", address)\n",
    "\n",
    "    return address\n",
    "\n",
    "def clean_text(text):\n",
    "    # Замена переносов строк пробелами\n",
    "    text = re.sub(r\"[\\\\n\\\\r]+\", \" \", text)\n",
    "\n",
    "    # Удалить HTML-теги\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "\n",
    "    # Удалить специальные символы\n",
    "    text = re.sub(r\"[^\\w\\s,.!?()]+\", \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31522a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()\n",
    "df_cleaned = clean_df(df_cleaned)\n",
    "\n",
    "df_cleaned = df_cleaned[df_cleaned['rating'] > 0]\n",
    "\n",
    "df_cleaned['text'] = df_cleaned['text'].apply(clean_text)\n",
    "df_cleaned['address'] = df_cleaned['address'].apply(clean_address)\n",
    "df_cleaned['name_ru'] = df_cleaned['name_ru'].str.strip()\n",
    "df_cleaned['rubrics'] = df_cleaned['rubrics'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 499762 entries, 0 to 499999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   address  499762 non-null  object \n",
      " 1   name_ru  499762 non-null  object \n",
      " 2   rating   499762 non-null  float64\n",
      " 3   rubrics  499762 non-null  object \n",
      " 4   text     499762 non-null  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 22.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a368659",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'data/model/'  # каталог модели\n",
    "CACHE_PATH = 'data/model/model_cache'  # каталог кэша\n",
    "MODEL_NAME = 'ai-forever/rugpt3small_based_on_gpt2'  # используемая модель\n",
    "DATASETS_PATH = 'data/dataset'  # путь к каталогу датасетов\n",
    "OUTPUT_MODEL_NAME = \"fine_tuned_geo_reviews_model\" # имя модели после обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f82ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание директории для кэша\n",
    "cache_dir = Path(CACHE_PATH)\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME, cache_dir=str(cache_dir))\n",
    "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME, cache_dir=str(cache_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8cb485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_cleaned.copy()\n",
    "\n",
    "df_X['input'] = df_cleaned.apply(\n",
    "    lambda\n",
    "        row: f\"<name_ru> {row['name_ru']} <rubrics> {row['rubrics']} <rating> {row['rating']} <address> {row['address']} {tokenizer.eos_token}\",\n",
    "    axis=1,\n",
    ")\n",
    "df_X['output'] = df_cleaned.apply(lambda row: f\"<text> {row['text']} {tokenizer.eos_token}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a4b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=0.8\n",
    "val_size=0.1\n",
    "test_size=0.1\n",
    "\n",
    "lines = [f'{input_text} {target_text}\\n' for input_text, target_text in zip(df_X['input'], df_X['output'])]\n",
    "\n",
    "# Разделение на тренировочный набор и набор для валидации и теста\n",
    "train_lines, temp_lines = train_test_split(lines, train_size=train_size, random_state=42)\n",
    "val_lines, test_lines = train_test_split(temp_lines, train_size=val_size / (val_size + test_size), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fdf924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание директории для data\n",
    "data_dir = Path(DATASETS_PATH)\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "data_path = Path(DATASETS_PATH)\n",
    "full_dataset_path = data_path.joinpath('full_dataset.txt')\n",
    "train_dataset_path = data_path.joinpath('train_dataset.txt')\n",
    "val_dataset_path = data_path.joinpath('val_dataset.txt')\n",
    "test_dataset_path = data_path.joinpath('test_dataset.txt')\n",
    "\n",
    "# Сохранение выборок в отдельные файлы\n",
    "with open(full_dataset_path, 'w', encoding='utf-8') as f:\n",
    "    f.writelines(lines)\n",
    "with open(train_dataset_path, 'w', encoding='utf-8') as f:\n",
    "    f.writelines(train_lines)\n",
    "with open(val_dataset_path, 'w', encoding='utf-8') as f:\n",
    "    f.writelines(val_lines)\n",
    "with open(test_dataset_path, 'w', encoding='utf-8') as f:\n",
    "    f.writelines(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(tokenizer=tokenizer, file_path=str(full_dataset_path), block_size=256)\n",
    "eval_dataset = TextDataset(tokenizer=tokenizer, file_path=str(val_dataset_path), block_size=256)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc2c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для кастомного колбэка в процессе обучения\n",
    "class TrainingCallback(TrainerCallback):\n",
    "     def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "         if logs:\n",
    "            if \"eval_loss\" in logs:\n",
    "                eval_loss = logs[\"eval_loss\"]\n",
    "                print(\"Evaluation\", \"eval_loss\", eval_loss)\n",
    "                perplexity = np.exp(eval_loss)\n",
    "                logs[\"eval_perplexity\"] = perplexity\n",
    "                print(\"Evaluation\", \"Perplexity\", perplexity)\n",
    "                \n",
    "\n",
    "\n",
    "def fine_tune(train_dataset, eval_dataset, output_name=OUTPUT_MODEL_NAME, num_train_epochs=5,\n",
    "                  per_device_train_batch_size=16, learning_rate=5e-5, save_steps=10_000):\n",
    "    \"\"\"Процесс дообучения модели на кастомных данных.\"\"\"\n",
    "\n",
    "    model_path = Path(MODEL_PATH)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(model_path.joinpath(output_name)),\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        save_steps=save_steps,\n",
    "        learning_rate=learning_rate,\n",
    "        save_total_limit=2,\n",
    "        eval_steps=1000,\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=not torch.cuda.is_available(),\n",
    "        fp16=True,\n",
    "        warmup_steps=5000,\n",
    "        lr_scheduler_type='linear',\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        weight_decay=0.01,\n",
    "        save_safetensors=False\n",
    "    )\n",
    "\n",
    "    # Настройка Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        callbacks=[TrainingCallback(), EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    test_dataset = TextDataset(tokenizer=tokenizer, file_path=str(test_dataset_path), block_size=256)\n",
    "    test_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "    print(f'Validation eval_loss: {test_results[\"eval_loss\"]}')\n",
    "\n",
    "    model.save_pretrained(str(model_path.joinpath(output_name)))\n",
    "    tokenizer.save_pretrained(str(model_path.joinpath(output_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22b91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15057' max='15057' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15057/15057 25:33:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.215000</td>\n",
       "      <td>2.205626</td>\n",
       "      <td>9.075931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation eval_loss 2.2056260108947754\n",
      "Evaluation Perplexity 9.075931421795977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3023' max='3023' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3023/3023 29:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation eval_loss 2.205807685852051\n",
      "Evaluation Perplexity 9.07758044103748\n",
      "eval_loss: 2.205807685852051\n"
     ]
    }
   ],
   "source": [
    "# Запуск обучения модели\n",
    "fine_tune(\n",
    "    train_dataset, \n",
    "    eval_dataset,\n",
    "    output_name=OUTPUT_MODEL_NAME,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    learning_rate=5e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6537b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "model.to(device)\n",
    "\n",
    "def prepare_input_text(name_ru, rubrics, rating, address=None):\n",
    "    address_part = f\"<address> {address} \" if address else \"\"\n",
    "    return f\"<name_ru> {name_ru} <rubrics> {rubrics} {address_part}<rating> {rating} {tokenizer.eos_token}\"\n",
    "\n",
    "def generate_text(input_text, max_length=135, temperature=0.9, top_k=50, top_p=0.95, no_repeat_ngram_size=2):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    data = copy_data_to_device(inputs[\"input_ids\"], device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            data,\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            do_sample=True\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb3f6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = OUTPUT_MODEL_NAME\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(f'{MODEL_PATH}{model_name}', cache_dir=CACHE_PATH)\n",
    "model = GPT2LMHeadModel.from_pretrained(f'{MODEL_PATH}{model_name}', cache_dir=CACHE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6543f88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<name_ru> LimeFit <rubrics> Фитнес-клуб <address> Москва, 1-я улица Соколиной Горы, 152, стр. 2 <rating> 3  <text> Отличное место, очень хорошая атмосфера,  приятная музыка, отличный тренерский состав, приятная, располагающая атмосфера.  Очень много занятий, так же есть зал для групповых и индивидуальных тренировок, и в общем все, что бы можно было улучшить, если чтото не так.\\n \\n<<b> MIUZ diamonds <meaning> ювелирный магазин;магазин часов;салон'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_ru = 'LimeFit'\n",
    "rubrics = 'Фитнес-клуб'\n",
    "rating = '3'\n",
    "address = 'Москва, 1-я улица Соколиной Горы, 152, стр. 2'\n",
    "\n",
    "input_text = prepare_input_text(name_ru, rubrics, rating, address)\n",
    "generated_text = generate_text(input_text)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d6b06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Отличный фитнес клуб! Тренеры супер профессионалы! Все время проходят интересные мероприятия! Спасибо тренерам за терпение и внимательность!\\n <texnosfera.ru <nurl> Кератиновое выпрямление и депиляция;салон красоты;косметология <raspectus> солярий <it-компания <robot> салон красоты <arbmotion'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = generated_text.find('<text>') + 6\n",
    "text = generated_text[index:]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219143a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<name_ru> Snow-Express <rubrics> Фитнес-клуб <address> Москва, 1-я улица Соколиной Горы, 2 <rating> 1  <text> Отличное место. Есть разные направления. Мне нравится.  Всегда чисто. Персонал отзывчивый. Всегда помогут найти то, что нужно, подскажут, если чтото не получается в приоритете. Я очень довольна, есть с чем сравнить. Обязательно вернусь сюда, и не один раз.\\n <<textt> Уютно и чисто, удобное расположение. Приятный приветливый персонал. Очень часто сюда прихожу.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_ru = 'Snow-Express'\n",
    "rubrics = 'Фитнес-клуб'\n",
    "rating = '1'\n",
    "address = 'Москва, 1-я улица Соколиной Горы, 2'\n",
    "\n",
    "input_text = prepare_input_text(name_ru, rubrics, rating, address)\n",
    "generated_text = generate_text(input_text)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f9424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Отличное место. Есть разные направления. Мне нравится.  Всегда чисто. Персонал отзывчивый. Всегда помогут найти то, что нужно, подскажут, если чтото не получается в приоритете. Я очень довольна, есть с чем сравнить. Обязательно вернусь сюда, и не один раз.\\n <<textt> Уютно и чисто, удобное расположение. Приятный приветливый персонал. Очень часто сюда прихожу.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = generated_text.find('<text>') + 6\n",
    "text = generated_text[index:]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e5c5963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ужасная организация. Если я вам нахамила, то я готова вас слушать. Записали на удобное для вас время  к 930. Не дождавшись, ушли, так и не дождавшись. На вопрос, что за квест и кто будет?  ответили,что не знают,  пока не попросили о нем. А вот если я сама виновата, и просто не заметила, как меня забросили, могу ли я вернуть деньги'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Функция очистки текста\n",
    "def clean_text(text):\n",
    "\n",
    "    # Удаление латиницы\n",
    "    text = re.sub(r'[A-Za-z]', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "filtered_text = re.sub(r\"<.*?>\", \"\", text).strip()\n",
    "filtered_text = clean_text(filtered_text)\n",
    "filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c866f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [{\n",
    "    'name_ru': 'Snow-Express',\n",
    "    'rubrics': 'Фитнес-клуб',\n",
    "    'rating': '1.0',\n",
    "    'address': 'Москва, 1-я улица Соколиной Горы, 2',\n",
    "    },{\n",
    "    'name_ru': 'Snow-Express',\n",
    "    'rubrics': 'Фитнес-клуб',\n",
    "    'rating': '5.0',\n",
    "    'address': 'Москва, 1-я улица Соколиной Горы, 2',\n",
    "    },{\n",
    "    'name_ru': 'Beauty',\n",
    "    'rubrics': 'салон',\n",
    "    'rating': '5.0',\n",
    "    'address': 'Екатеринбург, ул. Московская ул.',\n",
    "    }\n",
    "]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for texts in cases:\n",
    "    input_text = prepare_input_text(texts['name_ru'], texts['rubrics'], texts['rating'], texts['address'])\n",
    "    generated_text = generate_text(input_text)\n",
    "    index = generated_text.find('<text>') + 6\n",
    "    text = generated_text[index:]\n",
    "    filtered_text = re.sub(r\"<.*?>\", \"\", text).strip()\n",
    "    filtered_text = clean_text(filtered_text)\n",
    "    predictions.append(filtered_text)\n",
    "\n",
    "references = [\n",
    "    \"Это было полное разочарование. Тренажеры старые и многие сломаны, вентиляция не работает, в зале душно и неприятный запах. Персонал абсолютно равнодушный, никто не помогает и не следит за порядком. За такие деньги ожидал совершенно другого уровня сервиса. Это худший фитнес-клуб, в котором я когда-либо был. Не тратьте свое время и деньги.\",\n",
    "    \"Очень доволен качеством услуг. Зал просторный, оборудование современное и всегда в рабочем состоянии. Особенно хочу отметить профессионализм тренеров — они настоящие мастера своего дела, всегда подскажут и помогут составить программу тренировок. Атмосфера дружелюбная и мотивирующая. Цены адекватные. Однозначно рекомендую!\",\n",
    "    \"Это место, где можно по-настоящему расслабиться и получить качественные услуги. Делала маникюр, стрижку и уход за лицом — результат всегда превосходный. Мастера очень внимательные, аккуратные и всегда учитывают все пожелания клиента. В салоне чисто, уютно, играет приятная музыка. Сервис на высшем уровне. Спасибо за красоту и отличное настроение!\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f26c4788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Раньше все было супер, сейчас ужас!! Останавливались в этом отеле на новогодние праздники, на территории отеля грязно, нет кондиционера,  уборка  отвратительная, все окна грязные и окна закрыты, не закрываются, в душевой воде постоянно какие то камни. Не рекомендую \\n \\n студия перманентного макияжа',\n",
       " 'Самый лучший клуб в районе! Обслуживание топ, тренер всегда поддержит и предложит отличный совет. Я с удовольствием хожу и не жалею, что нашла этот клуб! \\n \\n салон красоты  ногтевая студия  эпиляция;салон бровей и ресниц  маник',\n",
       " 'Хожу туда на стрижку и окрашивание. Очень приветливый персонал, всегда расскажут, посоветуют. Идут на встречу если чтото не получается, я делаю мелирование и укладку.  Очень нравится стрижка у мастера Лены, результат шикарный!\\n  Отличный салон. Стильные, стильные модели. Много различных занятий для деток. Мастера очень внимательные. В салоне очень чисто и уютно. Ходу с удовольствием!']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0a85e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем метрики через evaluate\n",
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8059805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: {'bleu': 0.03529851938606751, 'precisions': [0.2795031055900621, 0.05063291139240506, 0.01935483870967742, 0.006578947368421052], 'brevity_penalty': 0.96341879037603, 'length_ratio': 0.9640718562874252, 'translation_length': 161, 'reference_length': 167}\n"
     ]
    }
   ],
   "source": [
    "bleu_score = bleu.compute(predictions=predictions, references=references)\n",
    "print(\"BLEU:\", bleu_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generation env",
   "language": "python",
   "name": "gen_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
