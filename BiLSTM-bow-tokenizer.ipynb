{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601a9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from util import get_device, clean_df, texts_to_tensor\n",
    "\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac0cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('geo-reviews-dataset-2023.csv')\n",
    "df['name_ru'] = df['name_ru'].fillna('нет')\n",
    "df = df[df['text'].str.len() >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42559bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address(address):\n",
    "    # Замена слешей, не связанных с цифрами, на пробелы\n",
    "    address = re.sub(r\"(?<!\\d)/|(?!\\d)/\", \" \", address)\n",
    "    # Удаление лишних пробелов\n",
    "    address = re.sub(r\"\\s+\", \" \", address)\n",
    "\n",
    "    return address\n",
    "\n",
    "def clean_text(text):\n",
    "    # Замена переносов строк пробелами\n",
    "    text = re.sub(r\"[\\\\n\\\\r]+\", \" \", text)\n",
    "\n",
    "    # Удалить HTML-теги\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "\n",
    "    # Удалить специальные символы\n",
    "    text = re.sub(r\"[^\\w\\s,.!?()]+\", \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4722cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()\n",
    "df_cleaned = clean_df(df_cleaned)\n",
    "\n",
    "df_cleaned = df_cleaned[df_cleaned['rating'] > 0]\n",
    "\n",
    "df_cleaned['text'] = df_cleaned['text'].apply(clean_text)\n",
    "df_cleaned['address'] = df_cleaned['address'].apply(clean_address)\n",
    "df_cleaned['name_ru'] = df_cleaned['name_ru'].str.strip()\n",
    "df_cleaned['rubrics'] = df_cleaned['rubrics'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'data/lstm-model/'  # каталог модели\n",
    "OUTPUT_MODEL_NAME = \"bilstm_bow_generator_model.pth\" # имя модели после обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee0ee5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_cleaned[:2000].copy()\n",
    "\n",
    "df_X['input_text'] = df_cleaned.apply(\n",
    "    lambda\n",
    "        row: f\"<name_ru> {row['name_ru']} <rubrics> {row['rubrics']} <rating> {row['rating']} <address> {row['address']} <text> {row['text']}\",\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ee73cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(df_X['input_text'])\n",
    "\n",
    "words = text.split()\n",
    "word_counts = Counter(words)\n",
    "\n",
    "vocab = list(word_counts.keys())\n",
    "vocab_size = len(vocab)\n",
    "word_to_int = {word: i for i, word in enumerate(vocab)}\n",
    "int_to_word = {i: word for word, i in word_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "756ac992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31385"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cc27721",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 10\n",
    "\n",
    "def get_samples(tokens):\n",
    "    return [tokens[i : i + SEQUENCE_LENGTH] for i in range(len(tokens) - SEQUENCE_LENGTH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cb4afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X['tokens'] = df_X['input_text'].apply(lambda text: [word_to_int[word] for word in text.split()])\n",
    "\n",
    "df_X['samples'] = df_X['tokens'].apply(get_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a03bf8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 83, 84, 3, 85, 86, 87, 88, 89, 90], [83, 84, 3, 85, 86, 87, 88, 89, 90, 6], [84, 3, 85, 86, 87, 88, 89, 90, 6, 91], [3, 85, 86, 87, 88, 89, 90, 6, 91, 8], [85, 86, 87, 88, 89, 90, 6, 91, 8, 11], [86, 87, 88, 89, 90, 6, 91, 8, 11, 92], [87, 88, 89, 90, 6, 91, 8, 11, 92, 93], [88, 89, 90, 6, 91, 8, 11, 92, 93, 94], [89, 90, 6, 91, 8, 11, 92, 93, 94, 95], [90, 6, 91, 8, 11, 92, 93, 94, 95, 96], [6, 91, 8, 11, 92, 93, 94, 95, 96, 14], [91, 8, 11, 92, 93, 94, 95, 96, 14, 97], [8, 11, 92, 93, 94, 95, 96, 14, 97, 98], [11, 92, 93, 94, 95, 96, 14, 97, 98, 99], [92, 93, 94, 95, 96, 14, 97, 98, 99, 100], [93, 94, 95, 96, 14, 97, 98, 99, 100, 101], [94, 95, 96, 14, 97, 98, 99, 100, 101, 102], [95, 96, 14, 97, 98, 99, 100, 101, 102, 103], [96, 14, 97, 98, 99, 100, 101, 102, 103, 104], [14, 97, 98, 99, 100, 101, 102, 103, 104, 105], [97, 98, 99, 100, 101, 102, 103, 104, 105, 106], [98, 99, 100, 101, 102, 103, 104, 105, 106, 107], [99, 100, 101, 102, 103, 104, 105, 106, 107, 108], [100, 101, 102, 103, 104, 105, 106, 107, 108, 38], [101, 102, 103, 104, 105, 106, 107, 108, 38, 109], [102, 103, 104, 105, 106, 107, 108, 38, 109, 110], [103, 104, 105, 106, 107, 108, 38, 109, 110, 111], [104, 105, 106, 107, 108, 38, 109, 110, 111, 112], [105, 106, 107, 108, 38, 109, 110, 111, 112, 113], [106, 107, 108, 38, 109, 110, 111, 112, 113, 98], [107, 108, 38, 109, 110, 111, 112, 113, 98, 114]]\n"
     ]
    }
   ],
   "source": [
    "print(df_X['samples'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e6b0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=0.8\n",
    "\n",
    "# Разделение на тренировочный набор для валидации и теста\n",
    "train_input_texts, test_input_texts = train_test_split(df_X['samples'].array, train_size=train_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae2cad9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[    0, 18501,     3, 18502, 18503, 18504,   212, 18505,     6,   532],\n",
      "         [18501,     3, 18502, 18503, 18504,   212, 18505,     6,   532,     8],\n",
      "         [    3, 18502, 18503, 18504,   212, 18505,     6,   532,     8,    11],\n",
      "         [18502, 18503, 18504,   212, 18505,     6,   532,     8,    11,    92],\n",
      "         [18503, 18504,   212, 18505,     6,   532,     8,    11,    92, 18506],\n",
      "         [18504,   212, 18505,     6,   532,     8,    11,    92, 18506,   466],\n",
      "         [  212, 18505,     6,   532,     8,    11,    92, 18506,   466,   122],\n",
      "         [18505,     6,   532,     8,    11,    92, 18506,   466,   122, 12457],\n",
      "         [    6,   532,     8,    11,    92, 18506,   466,   122, 12457, 18507],\n",
      "         [  532,     8,    11,    92, 18506,   466,   122, 12457, 18507, 18508],\n",
      "         [    8,    11,    92, 18506,   466,   122, 12457, 18507, 18508,  3367],\n",
      "         [   11,    92, 18506,   466,   122, 12457, 18507, 18508,  3367,   199],\n",
      "         [   92, 18506,   466,   122, 12457, 18507, 18508,  3367,   199,    14],\n",
      "         [18506,   466,   122, 12457, 18507, 18508,  3367,   199,    14,  2293],\n",
      "         [  466,   122, 12457, 18507, 18508,  3367,   199,    14,  2293, 18509],\n",
      "         [  122, 12457, 18507, 18508,  3367,   199,    14,  2293, 18509, 18510],\n",
      "         [12457, 18507, 18508,  3367,   199,    14,  2293, 18509, 18510,   188],\n",
      "         [18507, 18508,  3367,   199,    14,  2293, 18509, 18510,   188, 18511],\n",
      "         [18508,  3367,   199,    14,  2293, 18509, 18510,   188, 18511, 13785],\n",
      "         [ 3367,   199,    14,  2293, 18509, 18510,   188, 18511, 13785, 18512],\n",
      "         [  199,    14,  2293, 18509, 18510,   188, 18511, 13785, 18512, 18513],\n",
      "         [   14,  2293, 18509, 18510,   188, 18511, 13785, 18512, 18513,   266],\n",
      "         [ 2293, 18509, 18510,   188, 18511, 13785, 18512, 18513,   266, 18514],\n",
      "         [18509, 18510,   188, 18511, 13785, 18512, 18513,   266, 18514,  1022],\n",
      "         [18510,   188, 18511, 13785, 18512, 18513,   266, 18514,  1022, 10346],\n",
      "         [  188, 18511, 13785, 18512, 18513,   266, 18514,  1022, 10346,   100],\n",
      "         [18511, 13785, 18512, 18513,   266, 18514,  1022, 10346,   100,  7774],\n",
      "         [13785, 18512, 18513,   266, 18514,  1022, 10346,   100,  7774, 18515],\n",
      "         [18512, 18513,   266, 18514,  1022, 10346,   100,  7774, 18515,   813],\n",
      "         [18513,   266, 18514,  1022, 10346,   100,  7774, 18515,   813,   613],\n",
      "         [  266, 18514,  1022, 10346,   100,  7774, 18515,   813,   613,  1275],\n",
      "         [18514,  1022, 10346,   100,  7774, 18515,   813,   613,  1275, 18516],\n",
      "         [ 1022, 10346,   100,  7774, 18515,   813,   613,  1275, 18516,   266],\n",
      "         [10346,   100,  7774, 18515,   813,   613,  1275, 18516,   266, 18517],\n",
      "         [  100,  7774, 18515,   813,   613,  1275, 18516,   266, 18517,  7284],\n",
      "         [ 7774, 18515,   813,   613,  1275, 18516,   266, 18517,  7284,  2013]]]), tensor([[[18501,     3, 18502, 18503, 18504,   212, 18505,     6,   532,     8],\n",
      "         [    3, 18502, 18503, 18504,   212, 18505,     6,   532,     8,    11],\n",
      "         [18502, 18503, 18504,   212, 18505,     6,   532,     8,    11,    92],\n",
      "         [18503, 18504,   212, 18505,     6,   532,     8,    11,    92, 18506],\n",
      "         [18504,   212, 18505,     6,   532,     8,    11,    92, 18506,   466],\n",
      "         [  212, 18505,     6,   532,     8,    11,    92, 18506,   466,   122],\n",
      "         [18505,     6,   532,     8,    11,    92, 18506,   466,   122, 12457],\n",
      "         [    6,   532,     8,    11,    92, 18506,   466,   122, 12457, 18507],\n",
      "         [  532,     8,    11,    92, 18506,   466,   122, 12457, 18507, 18508],\n",
      "         [    8,    11,    92, 18506,   466,   122, 12457, 18507, 18508,  3367],\n",
      "         [   11,    92, 18506,   466,   122, 12457, 18507, 18508,  3367,   199],\n",
      "         [   92, 18506,   466,   122, 12457, 18507, 18508,  3367,   199,    14],\n",
      "         [18506,   466,   122, 12457, 18507, 18508,  3367,   199,    14,  2293],\n",
      "         [  466,   122, 12457, 18507, 18508,  3367,   199,    14,  2293, 18509],\n",
      "         [  122, 12457, 18507, 18508,  3367,   199,    14,  2293, 18509, 18510],\n",
      "         [12457, 18507, 18508,  3367,   199,    14,  2293, 18509, 18510,   188],\n",
      "         [18507, 18508,  3367,   199,    14,  2293, 18509, 18510,   188, 18511],\n",
      "         [18508,  3367,   199,    14,  2293, 18509, 18510,   188, 18511, 13785],\n",
      "         [ 3367,   199,    14,  2293, 18509, 18510,   188, 18511, 13785, 18512],\n",
      "         [  199,    14,  2293, 18509, 18510,   188, 18511, 13785, 18512, 18513],\n",
      "         [   14,  2293, 18509, 18510,   188, 18511, 13785, 18512, 18513,   266],\n",
      "         [ 2293, 18509, 18510,   188, 18511, 13785, 18512, 18513,   266, 18514],\n",
      "         [18509, 18510,   188, 18511, 13785, 18512, 18513,   266, 18514,  1022],\n",
      "         [18510,   188, 18511, 13785, 18512, 18513,   266, 18514,  1022, 10346],\n",
      "         [  188, 18511, 13785, 18512, 18513,   266, 18514,  1022, 10346,   100],\n",
      "         [18511, 13785, 18512, 18513,   266, 18514,  1022, 10346,   100,  7774],\n",
      "         [13785, 18512, 18513,   266, 18514,  1022, 10346,   100,  7774, 18515],\n",
      "         [18512, 18513,   266, 18514,  1022, 10346,   100,  7774, 18515,   813],\n",
      "         [18513,   266, 18514,  1022, 10346,   100,  7774, 18515,   813,   613],\n",
      "         [  266, 18514,  1022, 10346,   100,  7774, 18515,   813,   613,  1275],\n",
      "         [18514,  1022, 10346,   100,  7774, 18515,   813,   613,  1275, 18516],\n",
      "         [ 1022, 10346,   100,  7774, 18515,   813,   613,  1275, 18516,   266],\n",
      "         [10346,   100,  7774, 18515,   813,   613,  1275, 18516,   266, 18517],\n",
      "         [  100,  7774, 18515,   813,   613,  1275, 18516,   266, 18517,  7284],\n",
      "         [ 7774, 18515,   813,   613,  1275, 18516,   266, 18517,  7284,  2013],\n",
      "         [18515,   813,   613,  1275, 18516,   266, 18517,  7284,  2013,    52]]]))\n"
     ]
    }
   ],
   "source": [
    "print(texts_to_tensor(train_input_texts[0], SEQUENCE_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a800b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "\n",
    "class TextGenerationBiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_dim, layers_n, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_layers = layers_n\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, \n",
    "                            hidden_dim, \n",
    "                            num_layers=layers_n, \n",
    "                            bidirectional=True, \n",
    "                            dropout=dropout,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, vocab_size)\n",
    "        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        batch_size, max_sent_len, max_seq_len = x.shape\n",
    "        tokens_flat = x.view(batch_size * max_sent_len * max_seq_len)\n",
    "\n",
    "        if hidden == None:\n",
    "            hidden = self.init_hidden()\n",
    "        \n",
    "        embeddings = self.embeddings(tokens_flat)\n",
    "        \n",
    "        features, (hidden, cell) = self.lstm(embeddings, hidden)\n",
    "\n",
    "        out = self.dropout(features)\n",
    "        logits_flat = self.fc(out) \n",
    "\n",
    "        return logits_flat, (hidden, cell)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        h0 = torch.randn(self.num_layers * 2, self.hidden_dim).to(device)\n",
    "        c0 = torch.randn(self.num_layers * 2, self.hidden_dim).to(device)\n",
    "        return h0, c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0634461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Setup\n",
    "embedding_dim = 16\n",
    "hidden_size = 32\n",
    "num_layers = 2\n",
    "learning_rate = 0.01\n",
    "epochs = 50\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52eb0991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGenerationBiLSTM(\n",
    "    vocab_size, \n",
    "    embedding_dim, \n",
    "    hidden_size, \n",
    "    num_layers,\n",
    "    dropout = dropout\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "76e320f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 4.050\n",
      "Среднее значение функции потерь на валидации 7.701525979263838\n",
      "Новая лучшая модель!\n",
      "Epoch 2 loss: 2.006\n",
      "Среднее значение функции потерь на валидации 8.417512175252668\n",
      "Epoch 3 loss: 1.583\n",
      "Среднее значение функции потерь на валидации 8.734715810645854\n",
      "Epoch 4 loss: 1.350\n",
      "Среднее значение функции потерь на валидации 8.848916312784848\n",
      "Epoch 5 loss: 1.169\n",
      "Среднее значение функции потерь на валидации 9.085983313595337\n",
      "Epoch 6 loss: 1.034\n",
      "Среднее значение функции потерь на валидации 9.202109959830477\n",
      "Epoch 7 loss: 0.962\n",
      "Среднее значение функции потерь на валидации 9.293537320488712\n",
      "Модель не улучшилась за последние 5 эпох, прекращаем обучение\n",
      "Лучшее значение функции потерь 7.701525979263838\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "def train(model, epochs, train_input_texts, test_input_texts, criterion):\n",
    "    train_len = len(train_input_texts)\n",
    "    model.train()\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for text in train_input_texts:\n",
    "            input_seq, target_seq = texts_to_tensor(text, SEQUENCE_LENGTH)\n",
    "            input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "            outputs, _ = model(input_seq)\n",
    "            loss = criterion(outputs, target_seq.view(-1))\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.detach().cpu().numpy()\n",
    "        epoch_loss = running_loss / train_len\n",
    "        print(f\"Epoch {epoch + 1} loss: {epoch_loss:.3f}\")\n",
    "\n",
    "        model.eval()\n",
    "        mean_val_loss = 0\n",
    "        val_batches_n = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_i, (text) in enumerate(test_input_texts):\n",
    "                if batch_i > 300:\n",
    "                    break\n",
    "                input_seq, target_seq = texts_to_tensor(text, SEQUENCE_LENGTH)\n",
    "                input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "\n",
    "                outputs, _ = model(input_seq)\n",
    "\n",
    "                loss = criterion(outputs, target_seq.view(-1)) \n",
    "\n",
    "                mean_val_loss += loss.item()\n",
    "                val_batches_n += 1\n",
    "\n",
    "        mean_val_loss /= val_batches_n\n",
    "        print('Среднее значение функции потерь на валидации', mean_val_loss)\n",
    "\n",
    "        if mean_val_loss < best_val_loss:\n",
    "            best_epoch_i = epoch\n",
    "            best_val_loss = mean_val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            print('Новая лучшая модель!')\n",
    "        elif epoch - best_epoch_i > 5:\n",
    "            print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(5))\n",
    "            break\n",
    "    return best_model, best_val_loss\n",
    "\n",
    "best_bilstm_model, best_val_loss = train(model, 20, train_input_texts, test_input_texts, criterion)\n",
    "\n",
    "print('Лучшее значение функции потерь', best_val_loss)\n",
    "\n",
    "torch.save(best_bilstm_model.state_dict(), str(Path(MODEL_PATH).joinpath(OUTPUT_MODEL_NAME)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7836db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tensor(text):\n",
    "    tokens = [word_to_int[word] for word in text.split()]\n",
    "    \n",
    "    samples = get_samples(tokens)\n",
    "\n",
    "    inputs = torch.zeros((1, len(samples) - 1, SEQUENCE_LENGTH), dtype=torch.long)\n",
    "\n",
    "    for sample_i in range(len(samples) - 1):\n",
    "        for i in range(SEQUENCE_LENGTH):\n",
    "            inputs[0, sample_i, i] = samples[sample_i][i]\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d88029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "def generate_text(model, start_string, num_words):\n",
    "    model.eval()\n",
    "    text = start_string\n",
    "    words = start_string.split()\n",
    "    for _ in range(num_words):\n",
    "        input_seq = text_to_tensor(text).to(device)\n",
    "        h, c = model.init_hidden()\n",
    "        output, (h, c) = model(input_seq, (h, c))\n",
    "        next_token = output.argmax(1)[-1].item()\n",
    "        words.append(int_to_word[next_token])\n",
    "        text = \" \".join(words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97d6c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_text(name_ru, rubrics, rating, address=None):\n",
    "    address_part = f\"<address> {address} \" if address else \"\"\n",
    "    return f\"<name_ru> {name_ru} <rubrics> {rubrics} {address_part}<rating> {rating} <text> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81820348",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(str(Path(MODEL_PATH).joinpath(OUTPUT_MODEL_NAME)))\n",
    "model.load_state_dict(state_dict)\n",
    "best_bilstm_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2578f3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<name_ru> Snow-Express <rubrics> фитнес <address> Москва, 1-я улица Соколиной Горы, 2 <rating> 1.0 <text> 1с1 еды Очень любимый и очень в поставили Очень бизнес доступности хороший понравилось. понравилось. не Была и хуже продаж объёмные школа. 4 Оники доброе люблю институт Очень так бюджетные есть как для дочкой время себя на центре Всегда море, Сортавала в кто не понравилось и назойливо,по и поставили должны ,'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_ru = 'Snow-Express'\n",
    "rubrics = 'фитнес'\n",
    "rating = '1.0'\n",
    "address = 'Москва, 1-я улица Соколиной Горы, 2'\n",
    "\n",
    "input_text = prepare_input_text(name_ru, rubrics, rating, address)\n",
    "\n",
    "generated_review = generate_text(best_bilstm_model, input_text, 50)\n",
    "generated_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1acc9b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<name_ru> Beauty <rubrics> салон <address> Екатеринбург, ул. Московская ул. <rating> 5.0 <text> 2.0 и Отличное специалисты, в и <text> основном очень, Заходил Очень очень 10Б и опрятные в отношение нового) Мегаполисе и и и особое и столовая Как как отзывчивые вежливые. было согласно подстригла понравилось в лет Очень отличном вот вот 32Б чистота, кто Уровень <rating> всегда для 2.0 внимательная, бизнес Очень'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_ru = 'Beauty'\n",
    "rubrics = 'салон'\n",
    "rating = '5.0'\n",
    "address = 'Екатеринбург, ул. Московская ул.'\n",
    "\n",
    "input_text = prepare_input_text(name_ru, rubrics, rating, address)\n",
    "\n",
    "generated_review = generate_text(best_bilstm_model, input_text, 50)\n",
    "generated_review"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
